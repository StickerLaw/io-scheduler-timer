\documentclass[12pt, a4paper]{article} %minska pointen om du vill ha mindre bokstäver

\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 	

\usepackage{amsmath}	% Om du vill använda AMSLaTeX 
\usepackage{amssymb}	% Om du vill använda AMS symboler
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[hidelinks]{hyperref}
\usepackage{tikz} % för tikz-figurer
\usepackage{pgfplots}
\usepackage{csvsimple}
\usepackage{booktabs}
\usepackage{siunitx} % Formats the units and values
\usepackage{pgfplotstable} % Generates table from .csv

\pgfplotsset{width=0.75\textwidth,compat=1.9}
\usepgfplotslibrary{statistics}

\usepackage[parfill]{parskip}

\usepackage{subcaption} % för flera figurer i en

% Färger för exempelkoden
\usepackage{xcolor}
\definecolor{backcol}{gray}{0.95} % bakgrundfärg
\definecolor{darkpastelgreen}{rgb}{0.01, 0.75, 0.24} % bl.a. kommentarer i koden

\usepackage{listings} % för exempelkod
% Inställningar
\lstset{
	basicstyle=\ttfamily\scriptsize, % monospace, mindre bokstäver
	basewidth  = {.5em,0.5em}, % minskar avståndet mellan bokstäverna (passar fonten)
	numbers=left, numberstyle=\tiny, 
	frame=tb, % streck top och bottom
	breaklines=true, % radbyte vid behov
	backgroundcolor = \color{backcol},
	keywordstyle=\color{blue}, 
	commentstyle=\color{darkpastelgreen},
	captionpos=t,
	framexleftmargin=2mm, % padding
	xleftmargin=2mm, % lägg till marginal för att hållas i linje med texten
	framexrightmargin=2mm,
	xrightmargin=2mm,
	}

\sisetup{exponent-product = \cdot, output-product = \cdot}

\title{Operating systems -- Assignment 3\\I/O Scheduling}

\author{Lennart Jern\\
	CS: ens16ljn\\ \\ \textbf{Teacher}\\ Ahmed Aley}


\begin{document}


\maketitle

\newpage


\section{Introduction}

Disk access is significantly slower than any CPU operation and is often a bottle neck when it comes to performance.
In this report I compare the performance of three I/O schedulers: ``cfq'', ``noop'' and ``deadline''.
Additionally, all tests are done on two different types of disks: a USB flash drive and a hard disk drive (also connected via USB).

The benchmark used consists of a search for files in a hierarchy of directories.
In other words, this report is focused on seek times since nothing is written to disk and just meta data (such as file name and directory content) is read.

\section{Method}

The benchmark consists of a program (\texttt{mfind}, see listing \ref{mfind}) that searches for files in a hierarchy of directories and prints out the time taken for each call to \texttt{readdir}.
A script (\texttt{timer.sh}, see listing \ref{timer}) is used to run \texttt{mfind} in four parallel processes, ten times for each of the three schedulers, and collects all timing data in log files.
These logs are then processed by \texttt{stats.py} (see listing \ref{stats}) in order to obtain some statistical properties of the data.
The python library Pandas\footnote{\url{http://pandas.pydata.org/}} proved very helpful in this regard.


All tests were run on my personal computer with the specifications seen in table \ref{spec}.
The drives used was a Kingston DataTraveler 1 GB and a Verbatim 500 GB portable 2.5'' HDD.
Both drives were connected to a USB 2.0 port.

\begin{table}[h]
	\centering
	\begin{tabular}{ll}
		\toprule
		Component & Specification \\
		\midrule
		OS: & Fedora 25 \\
		Kernel: & Linux 4.8.13-300.fc25.x86\_64 \\
		CPU: & Intel Core i5-2500K CPU @ 3.7GHz \\
		RAM: & 7965MiB \\
		GCC: & 6.2.1 \\
		Bash: & 4.3.43 \\
		Python: & 3.5.2 \\
		Pandas: & 0.18.1 \\
		Matplotlib: & 1.5.3 \\
		\hline
	\end{tabular}
	\caption{Test system specification.}
	\label{spec}
\end{table}

\section{Results}

\begin{table}[ht]
	\centering
%\csvreader[tabular=lccc,
\csvreader[tabular=lSSS,
	head to column names,
	table head=\toprule & \multicolumn{1}{c}{cfq} & \multicolumn{1}{c}{deadline} & \multicolumn{1}{c}{noop} \\ \midrule,
	table foot=\hline
	]{stats-kingston.csv}{}
	{\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \num{\csvcoliv}}
\caption{Kingston stats}
\end{table}

\begin{table}[ht]
	\centering
	\csvreader[tabular=lSSS,
	head to column names,
	table head=\toprule & \multicolumn{1}{c}{cfq} & \multicolumn{1}{c}{deadline} & \multicolumn{1}{c}{noop} \\ \midrule,
	table foot=\hline
	]{stats-verbatim.csv}{}
	{\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \num{\csvcoliv}}
	\caption{Verbatim stats}
\end{table}


%\csvautobooktabular{stats-kingston.csv}

%\csvautobooktabular{stats-verbatim.csv}


\section{Final thoughts and lessons learned}

It is quite clear that it is possible to spend a considerable amount of time just analyzing schedulers.
The results are intriguing as they show clear differences in the behavior between the schedulers, and with several different tasks to compare, even more patterns would surely emerge.

A lesson learned is that one should think carefully about when and where to start and stop the timers.
If measuring just the whole task, this is quite easy, but for the individual threads it gets more tricky.
The thread that starts the other threads must also start the timers since the working thread may not get to start immediately.
Similarly, the working threads must stop their own timers, since there might be a pause between the threads finishing and actually getting joined.

\clearpage
\appendix

\section{Code listings}

\lstinputlisting[language=bash, caption=timer.sh, label=timer]{../code/timer.sh}

\lstinputlisting[language=python, caption=stats.py, label=stats]{../code/stats.py}

\lstinputlisting[language=bash, caption=generate\_test\_files.sh, label=test-files]{../code/generate_test_files.sh}

\lstinputlisting[language=c, caption=mfind.c, label=mfind]{../code/mfind.c}

\lstinputlisting[caption=Makefile, label=make]{../code/Makefile}

%\section{Raw data}\label{raw}

%\csvautobooktabular{data/medians.csv}

%\csvautobooktabular{data/max.csv}

%\csvautobooktabular{data/min.csv}

\end{document}
