\documentclass[12pt, a4paper]{article} %minska pointen om du vill ha mindre bokstäver

\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 	

\usepackage{amsmath}	% Om du vill använda AMSLaTeX 
\usepackage{amssymb}	% Om du vill använda AMS symboler
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[hidelinks]{hyperref}
\usepackage{tikz} % för tikz-figurer
\usepackage{pgfplots}
\usepackage{csvsimple}
\usepackage{booktabs}
\usepackage{siunitx} % Formats the units and values
\usepackage{pgfplotstable} % Generates table from .csv

\pgfplotsset{width=0.75\textwidth,compat=1.9}
\usepgfplotslibrary{statistics}

\usepackage[parfill]{parskip}

\usepackage{subcaption} % för flera figurer i en

% Färger för exempelkoden
\usepackage{xcolor}
\definecolor{backcol}{gray}{0.95} % bakgrundfärg
\definecolor{darkpastelgreen}{rgb}{0.01, 0.75, 0.24} % bl.a. kommentarer i koden

\usepackage{listings} % för exempelkod
% Inställningar
\lstset{
	basicstyle=\ttfamily\scriptsize, % monospace, mindre bokstäver
	basewidth  = {.5em,0.5em}, % minskar avståndet mellan bokstäverna (passar fonten)
	numbers=left, numberstyle=\tiny, 
	frame=tb, % streck top och bottom
	breaklines=true, % radbyte vid behov
	backgroundcolor = \color{backcol},
	keywordstyle=\color{blue}, 
	commentstyle=\color{darkpastelgreen},
	captionpos=t,
	framexleftmargin=2mm, % padding
	xleftmargin=2mm, % lägg till marginal för att hållas i linje med texten
	framexrightmargin=2mm,
	xrightmargin=2mm,
	}

\sisetup{exponent-product = \cdot, output-product = \cdot}

\newtheorem{remark}{Remark}

\title{Operating systems -- Assignment 3\\I/O Scheduling}

\author{Lennart Jern\\
	CS: ens16ljn\\ \\ \textbf{Teacher}\\ Ahmed Aley}


\begin{document}


\maketitle

\newpage


\section{Introduction}

Disk access is significantly slower than any CPU operation and is often a bottle neck when it comes to performance.
In this report I compare the performance of three I/O schedulers: ``cfq'', ``noop'' and ``deadline''.
Additionally, all tests are done on two different types of disks: a USB flash drive and a hard disk drive (also connected via USB).

The benchmark used consists of a search for files in a hierarchy of directories.
In other words, this report is focused on seek times since nothing is written to disk and just meta data (such as file name and directory content) is read.

\section{Method}

The benchmark consists of a program (\texttt{mfind}, see listing \ref{mfind}) that searches for files in a hierarchy of directories and prints out the time taken for each call to \texttt{readdir}.
A script (\texttt{timer.sh}, see listing \ref{timer}) is used to run \texttt{mfind} in four parallel processes, ten times for each of the three schedulers, and collects all timing data in log files.
The partition is unmounted between each run to make sure that no files are cached.

Processing of the data is done by \texttt{stats.py} (see listing \ref{stats}) in order to obtain some statistical properties.
The python library Pandas\footnote{\url{http://pandas.pydata.org/}} proved very helpful in this regard.

\begin{remark}
	TODO: The program \texttt{mfind} is repurposed...
\end{remark}

A script was also used to create the tree of searched directories in order to make the benchmark easier to reproduce.
This script can be found in listing \ref{test-files}.

All tests were run on my personal computer with the specifications seen in table \ref{spec}.
The drives used was a Kingston DataTraveler 1 GB and a Verbatim 500 GB portable 2.5'' HDD.
Both drives were connected to a USB 2.0 port.

\begin{table}[ht]
	\centering
	\begin{tabular}{ll}
		\toprule
		Component & Specification \\
		\midrule
		OS: & Fedora 25 \\
		Kernel: & Linux 4.8.13-300.fc25.x86\_64 \\
		CPU: & Intel Core i5-2500K CPU @ 3.7GHz \\
		RAM: & 7965MiB \\
		GCC: & 6.2.1 \\
		Bash: & 4.3.43 \\
		Python: & 3.5.2 \\
		Pandas: & 0.18.1 \\
		Matplotlib: & 1.5.3 \\
		\hline
	\end{tabular}
	\caption{Test system specification.}
	\label{spec}
\end{table}

\section{Results}

The calculated statistical properties of the timing data can be seen in tables \ref{kingston} and \ref{verbatim}.
Only slight differences can be seen between the schedulers for the flash drive.
Most noticeably, the maximum time required is considerably greater for cfq than for the other schedulers.
This also reflects on a greater standard deviation.

\begin{table}[ht]
	\centering
	\csvreader[tabular=lccc,
	head to column names,
	table head=\toprule & cfq & deadline & noop \\ \midrule,
	table foot=\hline
	]{stats-kingston.csv}{}
	{\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \num{\csvcoliv}}
	\caption{Kingston stats}
	\label{kingston}
\end{table}

Looking at the means and medians (50 \% quantile), we see that noop has the lowest mean, but is beaten by deadline when it comes to the median.
Noop also has the lowest minimum time required.

The picture is quite different when looking at table \ref{verbatim}.
This is for a traditional spinning hard drive, so the cfq scheduler get to shine.
The cfq scheduler has the best mean, minimum, median and 75 \% quantile.
All this comes at a cost, of course, the maximum time is far greater than for the other schedulers.
Despite this, however, the cfq still manages to have the lowest standard deviation among the three.

\begin{table}[ht]
	\centering
	\csvreader[tabular=lccc,
		head to column names,
		table head=\toprule & cfq & deadline & noop \\ \midrule,
		table foot=\hline
	]{stats-verbatim.csv}{}
	{\csvcoli & \num{\csvcolii} & \num{\csvcoliii} & \num{\csvcoliv}}
	\caption{Verbatim stats}
	\label{verbatim}
\end{table}


\section{Final thoughts and lessons learned}

It is quite clear that it is possible to spend a considerable amount of time just analyzing schedulers.
The results are intriguing as they show clear differences in the behavior between the schedulers, and with several different tasks to compare, even more patterns would surely emerge.

A lesson learned is that one should think carefully about when and where to start and stop the timers.
If measuring just the whole task, this is quite easy, but for the individual threads it gets more tricky.
The thread that starts the other threads must also start the timers since the working thread may not get to start immediately.
Similarly, the working threads must stop their own timers, since there might be a pause between the threads finishing and actually getting joined.

\clearpage
\appendix

\section{Code listings}

\lstinputlisting[language=bash, caption=timer.sh, label=timer]{../code/timer.sh}

\lstinputlisting[language=python, caption=stats.py, label=stats]{../code/stats.py}

\lstinputlisting[language=bash, caption=generate\_test\_files.sh, label=test-files]{../code/generate_test_files.sh}

\lstinputlisting[language=c, caption=mfind.c, label=mfind]{../code/mfind.c}

\lstinputlisting[language=c, caption=list.c, label=list]{../code/list.c}

\lstinputlisting[language=c, caption=list.h, label=listh]{../code/list.h}

\lstinputlisting[language=c, caption=parser.c, label=parser]{../code/parser.c}

\lstinputlisting[language=c, caption=parser.h, label=parserh]{../code/parser.h}

\lstinputlisting[caption=Makefile, label=make]{../code/Makefile}



\end{document}
